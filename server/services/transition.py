# server/services/transition.py
# DJ Bridge Engine (Best Loop Extension)
# Strategy: Replace weak Outro with the extracted Best Loop from the same song.

import sys
import json
import os
import logging
import numpy as np
import librosa
import ffmpeg 
from scipy.spatial.distance import cdist

# ffmpeg.exe ê²½ë¡œ ì„¤ì •
current_dir = os.path.dirname(os.path.abspath(__file__))
if current_dir not in os.environ["PATH"]:
    os.environ["PATH"] += os.pathsep + current_dir

sys.stdout.reconfigure(encoding='utf-8')
sys.stderr.reconfigure(encoding='utf-8')

logging.basicConfig(level=logging.INFO, stream=sys.stderr)
logger = logging.getLogger(__name__)

# --- [Function 1] Best Loop Finder (Internal) ---
def find_best_loop_interval(file_path, bars=4):
    """
    ì˜¤ë””ì˜¤ íŒŒì¼ì„ ë¶„ì„í•˜ì—¬ ê°€ì¥ ë°˜ë³µì ì¸ 4ë§ˆë”” êµ¬ê°„ì˜ (ì‹œì‘, ë) ì‹œê°„ì„ ë°˜í™˜
    """
    try:
        y, sr = librosa.load(file_path, sr=22050) # ì†ë„ë¥¼ ìœ„í•´ 22kë¡œ ë¶„ì„
        tempo, beat_frames = librosa.beat.beat_track(y=y, sr=sr)
        beat_samples = librosa.frames_to_samples(beat_frames)
        
        beats_per_loop = 4 * bars # 4ë§ˆë”” = 16ë°•ì
        
        if len(beat_samples) < beats_per_loop + 1:
            return 0, 0 # ì‹¤íŒ¨ ì‹œ 0ì´ˆ ë°˜í™˜

        loops_specs = []
        loop_intervals = []

        # 1ë§ˆë””(4ë°•ì) ê°„ê²©ìœ¼ë¡œ ìœˆë„ìš° ì´ë™í•˜ë©° 4ë§ˆë””(16ë°•ì) êµ¬ê°„ ë¶„ì„
        for i in range(0, len(beat_samples) - beats_per_loop, 4):
            start = beat_samples[i]
            end = beat_samples[i + beats_per_loop]
            
            segment = y[start:end]
            if len(segment) < sr * 2.0: continue

            mels = librosa.feature.melspectrogram(y=segment, sr=sr, n_mels=128)
            mels_resized = librosa.util.fix_length(mels, size=128, axis=1) # í•´ìƒë„ ë‚®ì¶°ì„œ ë¹ ë¥¸ ë¹„êµ
            loops_specs.append(mels_resized.flatten())
            loop_intervals.append((start/sr, end/sr)) # ì´ˆ ë‹¨ìœ„ ì €ì¥

        if not loops_specs:
            return 0, 0

        # ìœ ì‚¬ë„ ë¶„ì„
        stack = np.array(loops_specs)
        mean_pattern = np.mean(stack, axis=0).reshape(1, -1)
        distances = cdist(stack, mean_pattern, metric='euclidean')
        best_idx = np.argmin(distances)
        
        return loop_intervals[best_idx] # (Start_Time, End_Time) ë°˜í™˜

    except Exception as e:
        logger.warning(f"Loop analysis failed: {e}")
        return 0, 0

# --- [Function 2] Main Blender ---
def create_blend_sequence(source_layers, target_layers, source_analysis, target_analysis, bars=4):
    try:
        logger.info(f"ğŸ›ï¸ ìŠ¤ë§ˆíŠ¸ íŠ¸ëœì§€ì…˜ ì‹œì‘ (Outro êµì²´ ëª¨ë“œ, {bars}ë§ˆë””)")
        
        base_dir = os.getcwd() 
        def resolve_path(p):
            if not os.path.isabs(p): return os.path.join(base_dir, p)
            return p

        for l in [source_layers, target_layers]:
            for k, v in l.items(): l[k] = resolve_path(v)

        # 1. ì •ë³´ ê³„ì‚°
        bpm_a = float(source_analysis.get('bpm', 120))
        bpm_b = float(target_analysis.get('bpm', 120))
        
        sec_per_bar_a = (60 / bpm_a) * 4
        sec_per_bar_b = (60 / bpm_b) * 4
        
        bridge_duration = sec_per_bar_a * bars
        b_intro_duration = sec_per_bar_b * bars
        
        # 2. ê³¡ A ê¸¸ì´ ì¸¡ì • (Outro ì‹œì ì„ ì•Œê¸° ìœ„í•´)
        def get_dur(p):
            try: return float(ffmpeg.probe(p)['format']['duration'])
            except: return 0.0
            
        dur_a = 0
        for p in source_layers.values():
            d = get_dur(p)
            if d > dur_a: dur_a = d
            
        # 3. â˜… í•µì‹¬: Song Aì˜ Best Loop êµ¬ê°„ ì°¾ê¸° â˜…
        # ë“œëŸ¼ íŠ¸ë™ì„ ê¸°ì¤€ìœ¼ë¡œ ë¶„ì„í•©ë‹ˆë‹¤.
        loop_start, loop_end = find_best_loop_interval(source_layers['drums'], bars=bars)
        loop_len = loop_end - loop_start
        
        if loop_len == 0:
            logger.warning("âš ï¸ ë£¨í”„ ì°¾ê¸° ì‹¤íŒ¨. ì¼ë°˜ Outroë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤.")
            loop_start = max(0, dur_a - bridge_duration)
            loop_len = bridge_duration

        logger.info(f"ğŸ” Song A Best Loop ë°œê²¬: {loop_start:.2f}ì´ˆ ~ {loop_end:.2f}ì´ˆ (ê¸¸ì´: {loop_len:.2f}s)")

        # -------------------------------------------------------------------
        # [PART 1] Song A Body
        # Outroê°€ ë‚˜ì˜¤ê¸° ì „ê¹Œì§€ë§Œ ì¬ìƒ (Best Loopë¡œ êµì²´í•  ê±°ë‹ˆê¹Œ)
        # -------------------------------------------------------------------
        cutoff_point = max(0, dur_a - bridge_duration)
        
        part1_inputs = [ffmpeg.input(source_layers[k]).filter('atrim', end=cutoff_point).filter('asetpts', 'PTS-STARTPTS') 
                        for k in ['vocals','drums','bass','other']]
        part1_mix = ffmpeg.filter(part1_inputs, 'amix', inputs=4, duration='shortest', dropout_transition=0)

        # -------------------------------------------------------------------
        # [PART 2] Bridge (Replacement)
        # ë°°ê²½: Song Aì˜ Best Loop (Outro ì•„ë‹˜!)
        # ì „ê²½: Song Bì˜ Intro Teaser (No Vocals)
        # -------------------------------------------------------------------
        
        # (A) Loop Background (Drums + Bass + Other)
        # VocalsëŠ” ëºë‹ˆë‹¤ (Loop êµ¬ê°„ì— ê°€ì‚¬ê°€ ìˆìœ¼ë©´ ì–´ìƒ‰í•  ìˆ˜ ìˆìŒ, ë³´í†µ Inst Loop ì„ í˜¸)
        bridge_bg_inputs = []
        for k in ['drums', 'bass', 'other']:
            # loop_start ì§€ì ì—ì„œ loop_len ë§Œí¼ ì˜ë¼ë‚´ê¸°
            stream = ffmpeg.input(source_layers[k]).filter('atrim', start=loop_start, duration=loop_len).filter('asetpts', 'PTS-STARTPTS')
            
            # ë§Œì•½ ë¸Œë¦¿ì§€ê°€ ë£¨í”„ë³´ë‹¤ ê¸¸ë©´(ê±°ì˜ ì—†ê² ì§€ë§Œ), ë£¨í•‘ ì²˜ë¦¬ (ì—¬ê¸°ì„  1íšŒë§Œ ì‚¬ìš© ê°€ì •)
            bridge_bg_inputs.append(stream)
            
        bridge_bg_mix = ffmpeg.filter(bridge_bg_inputs, 'amix', inputs=3, duration='longest', dropout_transition=0)
        
        # ê¸¸ì´ê°€ ëª¨ìë¼ë©´ ê°•ì œë¡œ ë§ì¶¤ (atrimì´ë‚˜ apad ì‚¬ìš© ê°€ëŠ¥í•˜ì§€ë§Œ, beat detectionì´ ì •í™•í•˜ë©´ ê±°ì˜ ë§ìŒ)

        # (B) Teaser Foreground (Song B Intro - No Vocals, No Drums)
        # Song Aì˜ BPMì— ë§ì¶° Time Stretch
        tempo_factor = bpm_a / bpm_b
        bridge_fg_inputs = []
        
        for k in ['bass', 'other']: # ë“œëŸ¼ë„ Bê³¡ êº¼ëŠ” ëºŒ (A ë£¨í”„ ë“œëŸ¼ì„ ì‚´ë¦¬ê¸° ìœ„í•´)
            stream = ffmpeg.input(target_layers[k]).filter('atrim', start=0, duration=b_intro_duration).filter('asetpts', 'PTS-STARTPTS')
            
            # Time Stretch
            ratio = tempo_factor
            while ratio > 2.0: stream = stream.filter('atempo', 2.0); ratio /= 2.0
            while ratio < 0.5: stream = stream.filter('atempo', 0.5); ratio /= 0.5
            if abs(ratio - 1.0) > 0.01: stream = stream.filter('atempo', ratio)
            
            bridge_fg_inputs.append(stream)
            
        bridge_fg_mix = ffmpeg.filter(bridge_fg_inputs, 'amix', inputs=2, duration='longest', dropout_transition=0)

        # Bridge Combine
        part2_mix = ffmpeg.filter([bridge_bg_mix, bridge_fg_mix], 'amix', inputs=2, duration='first', dropout_transition=0)

        # -------------------------------------------------------------------
        # [PART 3] Song B Start
        # -------------------------------------------------------------------
        part3_inputs = []
        for k in ['drums', 'bass', 'other', 'vocals']:
            part3_inputs.append(
                ffmpeg.input(target_layers[k])
                .filter('atrim', start=0) # ì²˜ìŒë¶€í„° ë‹¤ì‹œ ì‹œì‘
                .filter('asetpts', 'PTS-STARTPTS')
            )
        part3_mix = ffmpeg.filter(part3_inputs, 'amix', inputs=4, duration='longest', dropout_transition=0)

        # -------------------------------------------------------------------
        # [FINAL] Concat
        # -------------------------------------------------------------------
        final_output = ffmpeg.filter(
            [part1_mix, part2_mix, part3_mix],
            'concat', n=3, v=0, a=1
        )

        output_dir = os.path.join(base_dir, 'server', 'output', 'blends')
        os.makedirs(output_dir, exist_ok=True)
        output_filename = f"smart_trans_{bars}bars_{int(bpm_a)}.mp3"
        output_path = os.path.join(output_dir, output_filename)
        
        logger.info(f"ğŸ’¾ ë Œë”ë§ ì‹œì‘: {output_path}")
        ffmpeg.output(final_output, output_path, audio_bitrate='320k', acodec='libmp3lame').overwrite_output().run(quiet=True)
        
        return output_path

    except Exception as e:
        logger.error(f"Error: {str(e)}")
        raise

if __name__ == '__main__':
    if len(sys.argv) < 2:
        print(json.dumps({"error": "No input"}))
        sys.exit(1)
    
    try:
        input_arg = sys.argv[1]
        if os.path.isfile(input_arg):
            with open(input_arg, 'r', encoding='utf-8') as f: args = json.load(f)
        else:
            args = json.loads(input_arg)
        
        bars = int(args.get('blendPoint', 4)) # ê¸°ë³¸ 4ë§ˆë””
        
        output_path = create_blend_sequence(
            args['sourceLayers'], args['targetLayers'],
            args['sourceAnalysis'], args['targetAnalysis'],
            bars
        )
        print(json.dumps({"success": True, "outputPath": output_path}, ensure_ascii=False))
        
    except Exception as e:
        print(json.dumps({"success": False, "error": str(e)}, ensure_ascii=False))
        sys.exit(1)